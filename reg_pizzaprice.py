# -*- coding: utf-8 -*-
"""Reg_PizzaPrice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14-f7ihDX1QOq_PaEM9VIVsFLZvirBiq0

# Imports
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/reg_pizza_price.csv')
df

df.info()

df.describe()

"""# Inspecting Data"""

df['diameter'] = df['diameter'].str.replace('inch', '').astype(float)

df

df['price_rupiah'] = df['price_rupiah'].str.replace('Rp', '').str.replace(',', '').astype(int)

df

pip install ydata-profiling

from ydata_profiling import ProfileReport

ProfileReport(df)

df.plot(kind='box')

"""**Removing Outliers**"""

df['price_rupiah'].plot(kind='box')

df =df[~(df['price_rupiah'] > 150000)]

df['price_rupiah'].plot(kind='box')

df['diameter'].plot(kind='box')

df[df['diameter']>17]

df['price_rupiah'].describe()

df[df['price_rupiah']>98000]

"""# Feature Engineering & Data Preprocessing"""

df

"""**Encoding**"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['extra_sauce_encoded'] = le.fit_transform(df['extra_sauce'])

df[['extra_sauce_encoded','extra_sauce']].drop_duplicates()

df['extra_cheese_encoded'] = le.fit_transform(df['extra_cheese'])

df[['extra_cheese_encoded','extra_cheese']].drop_duplicates()

df['extra_mushrooms_encoded'] = le.fit_transform(df['extra_mushrooms'])

df[['extra_mushrooms_encoded','extra_mushrooms']].drop_duplicates()

df['size_encoded'] = le.fit_transform(df['size'])

df[['size_encoded', 'size']].drop_duplicates()

df['variant_encoded'] = le.fit_transform(df['variant'])

df[['variant_encoded', 'variant']].drop_duplicates()

df['topping_encoded'] = le.fit_transform(df['topping'])

df[['topping_encoded', 'topping']].drop_duplicates()

df['company_encoded'] = le.fit_transform(df['company'])

df[['company_encoded', 'company']].drop_duplicates()

df

"""**Splitting the Data**"""

X = df.drop(columns=['price_rupiah', 'extra_sauce', 'extra_cheese', 'extra_mushrooms', 'size', 'variant', 'topping', 'company'])
y = df['price_rupiah']

X

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_scaled = sc.fit_transform(X)

y_scaled = sc.fit_transform(y.values.reshape(-1, 1))

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)

"""# Building the Model"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score,mean_squared_error, mean_absolute_error
from sklearn.ensemble import  RandomForestRegressor
from xgboost import XGBRFRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline

lr = LinearRegression()
svr = SVR()
rfr = RandomForestRegressor()

xgb = XGBRFRegressor()

param1 = {}
param1['regressor'] = [lr]

param2 = {}
param2['regressor__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]
param2['regressor'] = [svr]

param3 = {}
param3['regressor__n_estimators'] = [50, 100, 200, 500]
param3['regressor__max_depth'] = [5, 10, 20]
param3['regressor'] = [rfr]

param4 = {}
param4['regressor'] = [xgb]
param4['regressor__max_depth'] = [5, 8,10, 20]
param4['regressor__n_estimators'] = [10,50, 100, 200, 500]

pipeline = Pipeline([('regressor', lr)])
params = [param1, param2, param3, param4]

from sklearn.model_selection import GridSearchCV
grid = GridSearchCV(pipeline, params, cv=5, scoring='r2')

grid.fit(X_train, y_train)

grid.best_params_

grid.best_score_

import joblib

joblib.dump(grid.best_estimator_, 'model.pkl')

my_model = joblib.load('model.pkl')

y_pred = my_model.predict(X_test)
y_pred = sc.inverse_transform(y_pred.reshape(-1, 1))

joblib.dump(X_scaled, 'scaler.pkl')

joblib.dump(y_scaled, 'traget_scaler.pkl')

